{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21834,
     "status": "ok",
     "timestamp": 1750333027395,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "-xTQW_oX-JPD",
    "outputId": "1f374ae8-b51b-42f4-9b4d-6e9fcd7bd84f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# prompt: connect to google drive\n",
    "#\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8379,
     "status": "ok",
     "timestamp": 1750333044920,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "Yuxy9NQn-gY8",
    "outputId": "f56135b7-b421-4ae9-a762-30dec6bf74f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matsim-tools in c:\\users\\jetschny\\appdata\\roaming\\python\\python312\\site-packages (0.0.19)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matsim-tools) (3.20.3)\n",
      "Requirement already satisfied: xopen>=1.7.0 in c:\\users\\jetschny\\appdata\\roaming\\python\\python312\\site-packages (from matsim-tools) (2.0.2)\n",
      "Requirement already satisfied: pandas>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matsim-tools) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=2.1.0->matsim-tools) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=2.1.0->matsim-tools) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=2.1.0->matsim-tools) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=2.1.0->matsim-tools) (2023.3)\n",
      "Requirement already satisfied: isal>=1.6.1 in c:\\users\\jetschny\\appdata\\roaming\\python\\python312\\site-packages (from xopen>=1.7.0->matsim-tools) (1.7.2)\n",
      "Requirement already satisfied: zlib-ng>=0.4.1 in c:\\users\\jetschny\\appdata\\roaming\\python\\python312\\site-packages (from xopen>=1.7.0->matsim-tools) (0.5.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->matsim-tools) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matsim-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 531,
     "status": "ok",
     "timestamp": 1750333045460,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "CHxi-aRM-pbc"
   },
   "outputs": [],
   "source": [
    "import matsim\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750333343473,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "RjHgEYWL-q-r"
   },
   "outputs": [],
   "source": [
    "#matsim outputs\n",
    "#plans_path = '/content/drive/MyDrive/ETC-DI_AP25/ABM/MATSim_outputs/berlin-v6.4.output_plans.xml.gz'\n",
    "#additional data\n",
    "#berlin_outline = \"/content/drive/MyDrive/ETC-DI_AP25/ABM/Berlin_Bezirke_dissolve.gpkg\"\n",
    "#AQ raster clipped by Berlin outline\n",
    "#NO2_annual_raster_Berlin = \"/content/drive/MyDrive/ETC-DI_AP25/ABM/NO2_2023/NO2_2023_epsg3035_clipBerlin.tif\"\n",
    "\n",
    "base_folder = \"Z:/Environment and Health/Air Quality/abm_no2/\"\n",
    "#matsim outputs\n",
    "network_path = 'berlin_data_matsim/berlin-v6.4.output_network.xml.gz'\n",
    "events_path = 'berlin_data_matsim/berlin-v6.4.output_events.xml.gz'\n",
    "plans_path = 'berlin_data_matsim/berlin-v6.4.output_plans.xml.gz'\n",
    "\n",
    "#additional data\n",
    "berlin_outline = \"berlin_data_shapes/Berlin_Bezirke_dissolve.gpkg\"\n",
    "#AQ raster clipped by Berlin outline\n",
    "NO2_annual_raster_Berlin = \"berlin_data_aq/NO2_2023_epsg3035_clipBerlin.tif\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uK8KVasO_6q2"
   },
   "source": [
    "# Static scenario\n",
    "\n",
    "Outline\n",
    "1. extract the **home location** of each (unique) agent\n",
    "2. limit the number of agents - use only the **Berlin city-based agents** (still over 300k agents)\n",
    "3. further **limit the number of agents** to selected value (e.g. to 3000)\n",
    "4. get **NO2 value at the home locations** & assign the **air pollution** to the agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tq5lIzlA2yR"
   },
   "source": [
    "#### How many agents in the scenario?\n",
    "\n",
    "informative cell, does not need to be run everytime (as long as the input plans file does not change), the num_agents is further hardcoded ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ei0XERxA_0W8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents in the scenario: 526111\n"
     ]
    }
   ],
   "source": [
    "# prompt: from the plans_path file can you extract how many people (Agents) are in the scenario?\n",
    "\n",
    "# Stream through a MATSim plans file.\n",
    "# The matsim.plan_reader returns a generator\n",
    "plans_generator = matsim.plan_reader(base_folder+plans_path)\n",
    "\n",
    "# To count unique persons, iterate through the generator and collect person IDs\n",
    "person_ids = set() # Using a set automatically handles uniqueness\n",
    "\n",
    "for person, plan in plans_generator:\n",
    "    # The person information is in the first element of the tuple\n",
    "    # The person object has attributes like 'id'\n",
    "    person_id = person.attrib.get('id')\n",
    "    if person_id: # Ensure the person id is not None or empty\n",
    "        person_ids.add(person_id)\n",
    "\n",
    "# Count the number of unique agents (persons)\n",
    "num_agents = len(person_ids)\n",
    "\n",
    "print(f\"Number of agents in the scenario: {num_agents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJNANxuqFWVC"
   },
   "source": [
    "### Subset of agents for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mnus3M6lBuKP"
   },
   "source": [
    "#### limit the agents by Berlin city boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 910,
     "status": "ok",
     "timestamp": 1750333934453,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "d78iKIKzB7aq"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import pyproj # Required for CRS transformation\n",
    "import random # For shuffling and random selection within cells\n",
    "import math # For ceil in grid calculation\n",
    "\n",
    "# Ensure pyproj is installed\n",
    "try:\n",
    "    import pyproj\n",
    "except ImportError:\n",
    "    # This might require a restart of the kernel in some environments\n",
    "    print(\"pyproj not found, attempting to install...\")\n",
    "    # !pip install pyproj # Uncomment if running in an environment where pip install works directly\n",
    "    import pyproj\n",
    "finally:\n",
    "    # Verify pyproj version if needed for specific functionalities\n",
    "    # print(f\"pyproj version: {pyproj.__version__}\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2513,
     "status": "ok",
     "timestamp": 1750334094596,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "ngPflGQSCCt3",
    "outputId": "b3676359-d1e9-40c5-ceae-7fbce5872af3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Berlin outline CRS: EPSG:3857\n",
      "Reprojected Berlin outline CRS: EPSG:3035\n"
     ]
    }
   ],
   "source": [
    "# Berlin boundary prep\n",
    "\n",
    "# Define the assumed CRS of the MATSim coordinates\n",
    "matsim_crs = 'EPSG:25832'\n",
    "\n",
    "# Load the Berlin boundary GeoPackage and ensure a valid CRS\n",
    "berlin_outline_gdf = gpd.read_file(base_folder+berlin_outline)\n",
    "\n",
    "# --- CRS Handling for Berlin Outline ---\n",
    "# Target CRS for intersection/containment checks. ETRS89-LAEA (EPSG:3035) is good for Europe-wide\n",
    "# analyses and should also be suitable for your raster data.\n",
    "target_crs_for_geometry_check = 'EPSG:3035'\n",
    "\n",
    "# Check if the GeoDataFrame has a CRS\n",
    "if berlin_outline_gdf.crs is None:\n",
    "    print(f\"Warning: Berlin outline GeoDataFrame has no CRS. Assuming {target_crs_for_geometry_check} based on previous context.\")\n",
    "    berlin_outline_gdf = berlin_outline_gdf.to_crs(target_crs_for_geometry_check) # Use to_crs even for initial set to ensure consistency\n",
    "else:\n",
    "    print(f\"Original Berlin outline CRS: {berlin_outline_gdf.crs}\")\n",
    "    if berlin_outline_gdf.crs != target_crs_for_geometry_check:\n",
    "        berlin_outline_gdf = berlin_outline_gdf.to_crs(target_crs_for_geometry_check)\n",
    "        print(f\"Reprojected Berlin outline CRS: {berlin_outline_gdf.crs}\")\n",
    "\n",
    "# Assuming berlin_outline_gdf contains a single polygon or a MultiPolygon representing Berlin\n",
    "# Dissolve if necessary and get the single geometry for easier checking\n",
    "berlin_geometry = berlin_outline_gdf.dissolve().geometry.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1342029,
     "status": "ok",
     "timestamp": 1750335721409,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "VmH0FU7QCrIe",
    "outputId": "0a0ebc2d-551b-4419-8aaf-c20e96ef0e61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting all eligible home locations within Berlin for spatial selection...\n",
      "Found 376991 total eligible home locations within Berlin.\n",
      "The Matsim pouints coordinates were reprojected to the EPSG:3035\n"
     ]
    }
   ],
   "source": [
    "# --- Process Plans and Collect All Eligible Home Locations (=within Berlin boundary)---\n",
    "\n",
    "# We will collect ALL agents whose home is within Berlin, then select from them.\n",
    "# if all points should be processed, the berlin_geometry.contains condition can be skipped\n",
    "\n",
    "all_eligible_home_locations = []\n",
    "processed_all_agents = set() # To ensure we only process each agent once\n",
    "\n",
    "print(f\"Collecting all eligible home locations within Berlin for spatial selection...\")\n",
    "# Re-initialize the plans generator to ensure we read from the beginning\n",
    "plans_generator = matsim.plan_reader(base_folder+plans_path)\n",
    "\n",
    "for person, plan in plans_generator:\n",
    "    agent_id = person.attrib.get('id')\n",
    "\n",
    "    if agent_id and agent_id not in processed_all_agents:\n",
    "        processed_all_agents.add(agent_id) # Mark as processed globally for this iteration\n",
    "\n",
    "        home_activity_found = False\n",
    "        for item in plan:\n",
    "            if item.tag == 'activity':\n",
    "                activity_type = item.attrib.get('type')\n",
    "                if activity_type and 'home' in activity_type.lower():\n",
    "                    home_x_str = item.attrib.get('x')\n",
    "                    home_y_str = item.attrib.get('y')\n",
    "\n",
    "                    if home_x_str is not None and home_y_str is not None:\n",
    "                        try:\n",
    "                            home_x = float(home_x_str)\n",
    "                            home_y = float(home_y_str)\n",
    "\n",
    "                            # Create GeoSeries for the MATSim point\n",
    "                            matsim_point_gs = gpd.GeoSeries([Point(home_x, home_y)], crs=matsim_crs)\n",
    "\n",
    "                            # Reproject the point to the Berlin outline's CRS\n",
    "                            reprojected_point_gs = matsim_point_gs.to_crs(berlin_outline_gdf.crs)\n",
    "                            reprojected_point = reprojected_point_gs.iloc[0]\n",
    "\n",
    "                            if berlin_geometry.contains(reprojected_point):\n",
    "                                all_eligible_home_locations.append({\n",
    "                                    'agent_id': agent_id,\n",
    "                                    'x_matsim': home_x, # Original MATSim X\n",
    "                                    'y_matsim': home_y, # Original MATSim Y\n",
    "                                    'geometry': reprojected_point # Reprojected geometry for spatial operations\n",
    "                                })\n",
    "                                # Found home within Berlin, move to the next agent\n",
    "                                home_activity_found = True\n",
    "                                break # Stop searching activities for this person\n",
    "                        except (ValueError, TypeError) as e:\n",
    "                            print(f\"Warning: Could not parse coordinates for agent {agent_id} home activity: {e}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error during CRS transformation for agent {agent_id}: {e}\")\n",
    "            if home_activity_found: # If a home activity was found for this person, no need to check other activities\n",
    "                break\n",
    "\n",
    "print(f\"Found {len(all_eligible_home_locations)} total eligible home locations within Berlin.\")\n",
    "print(f\"The Matsim pouints coordinates were reprojected to the {berlin_outline_gdf.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10019,
     "status": "ok",
     "timestamp": 1750335780601,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "Iyf74v6uDxQG",
    "outputId": "3949695f-61f8-4944-8627-c55568df102f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to csv\n"
     ]
    }
   ],
   "source": [
    "# prompt: export the agent_homes_df to csv\n",
    "agents_in_berlin_output_path = \"berlin_output/agents_berlin_city.csv\"\n",
    "\n",
    "# Convert the list of dictionaries to a pandas DataFrame\n",
    "all_eligible_home_locations_df = pd.DataFrame(all_eligible_home_locations)\n",
    "\n",
    "# Now call .to_csv() on the DataFrame\n",
    "all_eligible_home_locations_df.to_csv(base_folder+agents_in_berlin_output_path, index=False)\n",
    "print(\"DataFrame exported to csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38tr1dxNFbjk"
   },
   "source": [
    "#### limit the agents within Berlin boundaries by custom value (optional)\n",
    "\n",
    "agents selected within grid cells (to avoid clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 56,
     "status": "ok",
     "timestamp": 1750337206467,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "lO1_3kkEFfjd"
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import box # Import box here\n",
    "\n",
    "# --- Spatial Selection to Avoid Clustering ---\n",
    "# Strategy: Create a grid over Berlin and try to pick agents from different grid cells in a round-robin fashion.\n",
    "# This helps ensure spatial distribution.\n",
    "\n",
    "# Define grid size (adjust based on desired spread vs. number of agents)\n",
    "# A 10x10 grid on Berlin's bounding box might offer 100 cells. If we need 50 agents, this is good.\n",
    "# If num_agents_to_select_in_berlin is very high, consider fewer, larger cells.\n",
    "num_grid_cells_x = 10\n",
    "num_grid_cells_y = 10\n",
    "\n",
    "# Get bounding box of Berlin for grid creation\n",
    "minx, miny, maxx, maxy = berlin_geometry.bounds\n",
    "\n",
    "cell_width = (maxx - minx) / num_grid_cells_x\n",
    "cell_height = (maxy - miny) / num_grid_cells_y\n",
    "\n",
    "# Create grid cells (simple rectangular grid)\n",
    "grid_geometries = []\n",
    "for i in range(num_grid_cells_x):\n",
    "    for j in range(num_grid_cells_y):\n",
    "        # Create polygon for each grid cell using shapely.geometry.box\n",
    "        cell_geom = box(minx + i * cell_width, miny + j * cell_height,\n",
    "                        minx + (i + 1) * cell_width, miny + (j + 1) * cell_height)\n",
    "        grid_geometries.append(cell_geom)\n",
    "\n",
    "# Create a GeoDataFrame for the grid\n",
    "grid_gdf = gpd.GeoDataFrame(geometry=grid_geometries, crs=berlin_outline_gdf.crs)\n",
    "grid_gdf['grid_id'] = range(len(grid_gdf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 402
    },
    "executionInfo": {
     "elapsed": 3015,
     "status": "error",
     "timestamp": 1750337209476,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "ZcyoCq4xIy7o",
    "outputId": "58904fa8-7296-4118-dbb8-f60dd6bca1b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran out of grid cells with agents before selecting enough agents.\n",
      "\n",
      "Selected 2847 agents with spatially distributed home locations within Berlin.\n",
      "Selected Agent Home Locations GeoDataFrame (within Berlin):\n",
      "          agent_id       x_matsim      y_matsim  \\\n",
      "0  berlin_2a8ee486  783799.985857  5.824417e+06   \n",
      "1  berlin_816c5472  788869.771966  5.840491e+06   \n",
      "2  berlin_4f582033  802830.100512  5.831748e+06   \n",
      "3  berlin_4f389be6  786756.072566  5.838889e+06   \n",
      "4      bb_a7d85154  807365.300000  5.836209e+06   \n",
      "\n",
      "                          geometry  index_right  grid_id  \n",
      "0  POINT (4536986.598 3269901.216)           14       14  \n",
      "1  POINT (4542277.219 3285893.081)           28       28  \n",
      "2  POINT (4556102.395 3276956.337)           56       56  \n",
      "3   POINT (4540142.82 3284322.454)           18       18  \n",
      "4  POINT (4560695.642 3281349.743)           67       67  \n"
     ]
    }
   ],
   "source": [
    "num_agents_to_select_in_berlin = 3000\n",
    "\n",
    "# Create a GeoDataFrame from all eligible home locations\n",
    "all_eligible_agents_gdf = gpd.GeoDataFrame(\n",
    "    all_eligible_home_locations,\n",
    "    crs=berlin_outline_gdf.crs # Assign the CRS of the reprojected points ('EPSG:3035')\n",
    ")\n",
    "\n",
    "# Perform a spatial join to assign agents to grid cells\n",
    "# Use 'within' predicate to ensure points are strictly inside grid cells\n",
    "agents_with_grid = gpd.sjoin(all_eligible_agents_gdf, grid_gdf, how=\"left\", predicate=\"within\")\n",
    "\n",
    "# Group agents by grid cell and shuffle within each group\n",
    "shuffled_agents_by_grid = {}\n",
    "# Use .dropna(subset=['grid_id']) in case some agents fell outside the grid bounds due to floating point errors\n",
    "for grid_id, group in agents_with_grid.dropna(subset=['grid_id']).groupby('grid_id'):\n",
    "    # Convert grid_id to integer as it comes from the grid_gdf index\n",
    "    grid_id_int = int(grid_id)\n",
    "    # Convert to list of dictionaries for easier popping\n",
    "    shuffled_agents_by_grid[grid_id_int] = group.sample(frac=1, random_state=42).to_dict(orient='records')\n",
    "\n",
    "selected_agents_list = []\n",
    "\n",
    "# Get the list of grid_ids that actually contain agents\n",
    "active_grid_ids = list(shuffled_agents_by_grid.keys())\n",
    "if not active_grid_ids:\n",
    "    print(\"No agents fell into any grid cells during spatial join. Check CRSs or grid definition.\")\n",
    "    # Fallback to simple random selection if grid-based fails completely\n",
    "    if len(all_eligible_agents_gdf) > num_agents_to_select_in_berlin:\n",
    "        agent_home_locations_gdf = all_eligible_agents_gdf.sample(n=num_agents_to_select_in_berlin, random_state=42)\n",
    "    else:\n",
    "        agent_home_locations_gdf = all_eligible_agents_gdf\n",
    "    print(f\"\\nSelected {len(agent_home_locations_gdf)} agents using simple random sampling (due to grid issue).\")\n",
    "    print(\"Selected Agent Home Locations GeoDataFrame (within Berlin):\")\n",
    "    print(agent_home_locations_gdf.head())\n",
    "\n",
    "else:\n",
    "    # Shuffle the order of active grid_ids for a more random starting point\n",
    "    random.shuffle(active_grid_ids)\n",
    "    current_grid_idx = 0\n",
    "\n",
    "    # Iterate through grid cells, selecting one agent at a time in a round-robin fashion\n",
    "    # This ensures selection from different parts of the area before revisiting.\n",
    "    while len(selected_agents_list) < num_agents_to_select_in_berlin and active_grid_ids:\n",
    "        # Use modulo to cycle through the active grid IDs\n",
    "        grid_id_to_process = active_grid_ids[current_grid_idx % len(active_grid_ids)]\n",
    "\n",
    "        # Check if the grid_id exists in shuffled_agents_by_grid (it should if it's in active_grid_ids)\n",
    "        # and if there are agents left in that cell\n",
    "        if grid_id_to_process in shuffled_agents_by_grid and shuffled_agents_by_grid[grid_id_to_process]:\n",
    "            # Pop one agent from this cell's shuffled list\n",
    "            selected_agent_data = shuffled_agents_by_grid[grid_id_to_process].pop(0)\n",
    "            selected_agents_list.append(selected_agent_data)\n",
    "\n",
    "            # If this cell is now empty, remove it from the list of active_grid_ids\n",
    "            if not shuffled_agents_by_grid[grid_id_to_process]:\n",
    "                active_grid_ids.remove(grid_id_to_process)\n",
    "                # No need to adjust current_grid_idx explicitly here, the modulo takes care of it\n",
    "        else:\n",
    "              # This case should ideally not happen if active_grid_ids is correctly managed,\n",
    "              # but as a safeguard, remove the grid_id if it somehow points to an empty list\n",
    "              if grid_id_to_process in active_grid_ids:\n",
    "                  active_grid_ids.remove(grid_id_to_process)\n",
    "\n",
    "\n",
    "        # Move to the next grid cell in the shuffled order\n",
    "        if len(active_grid_ids) > 0: # Only move if there are still active grids\n",
    "            current_grid_idx = (current_grid_idx + 1) % len(active_grid_ids)\n",
    "        else: # All grid cells are exhausted\n",
    "            break\n",
    "\n",
    "    # Create the final GeoDataFrame of selected agents\n",
    "    if selected_agents_list:\n",
    "        # Separate geometry from attributes to create GeoDataFrame correctly\n",
    "        # Need to be careful here: the 'geometry' key was popped earlier,\n",
    "        # so we should reconstruct the DataFrame and then set the geometry column.\n",
    "        # A better approach might be to keep the geometry column during sampling.\n",
    "        # Let's refine the selection loop slightly.\n",
    "\n",
    "        # Re-implementing the selection to keep geometry column\n",
    "        selected_agents_with_geom = []\n",
    "        # Reset generators or use a fresh list of eligible agents if available\n",
    "        # Assuming `all_eligible_agents_gdf` is the full gdf of eligible agents\n",
    "        # Let's retry the sampling logic using this full gdf directly.\n",
    "\n",
    "        # A simpler approach: Group by grid_id and take the first N (or random) from each\n",
    "        # cell in a loop until 50 agents are selected.\n",
    "\n",
    "        selected_agent_ids_set = set()\n",
    "        selected_agents_list = [] # List of dictionaries including geometry\n",
    "\n",
    "        # Iterate through grid cells (shuffled order), selecting one agent per cell until target is met\n",
    "        grid_ids_order = list(shuffled_agents_by_grid.keys())\n",
    "        random.shuffle(grid_ids_order) # Shuffle grid order\n",
    "        grid_cycle = iter(grid_ids_order * math.ceil(num_agents_to_select_in_berlin / len(grid_ids_order))) # Cycle through grids\n",
    "\n",
    "        while len(selected_agent_ids_set) < num_agents_to_select_in_berlin and shuffled_agents_by_grid:\n",
    "            try:\n",
    "                current_grid_id = next(grid_cycle)\n",
    "            except StopIteration:\n",
    "                print(\"Ran out of grid cells with agents before selecting enough agents.\")\n",
    "                break # Stop if we've cycled through all grids with agents\n",
    "\n",
    "            if current_grid_id in shuffled_agents_by_grid and shuffled_agents_by_grid[current_grid_id]:\n",
    "                # Pop the next agent from this cell\n",
    "                agent_data = shuffled_agents_by_grid[current_grid_id].pop(0)\n",
    "                # Ensure agent_id is added to the set to track uniqueness\n",
    "                agent_id = agent_data['agent_id']\n",
    "                if agent_id not in selected_agent_ids_set:\n",
    "                    selected_agents_list.append(agent_data)\n",
    "                    selected_agent_ids_set.add(agent_id)\n",
    "\n",
    "            # If the list for this grid is now empty, remove the grid from consideration\n",
    "            if current_grid_id in shuffled_agents_by_grid and not shuffled_agents_by_grid[current_grid_id]:\n",
    "                del shuffled_agents_by_grid[current_grid_id]\n",
    "\n",
    "\n",
    "        if selected_agents_list:\n",
    "              # Create the final GeoDataFrame from the collected list\n",
    "              # Ensure the geometry column is correctly handled during GeoDataFrame creation\n",
    "              agent_home_locations_gdf = gpd.GeoDataFrame(selected_agents_list, crs=berlin_outline_gdf.crs)\n",
    "              print(f\"\\nSelected {len(agent_home_locations_gdf)} agents with spatially distributed home locations within Berlin.\")\n",
    "              print(\"Selected Agent Home Locations GeoDataFrame (within Berlin):\")\n",
    "              print(agent_home_locations_gdf.head())\n",
    "        else:\n",
    "              print(\"\\nNo agents selected after spatial sampling logic. Check if any agents fell within the grid.\")\n",
    "              # Fallback if grid sampling somehow yields no results\n",
    "              if len(all_eligible_agents_gdf) > num_agents_to_select_in_berlin:\n",
    "                agent_home_locations_gdf = all_eligible_agents_gdf.sample(n=num_agents_to_select_in_berlin, random_state=42)\n",
    "              else:\n",
    "                agent_home_locations_gdf = all_eligible_agents_gdf\n",
    "              print(f\"\\nSelected {len(agent_home_locations_gdf)} agents using simple random sampling (due to grid sampling issue).\")\n",
    "              print(\"Selected Agent Home Locations GeoDataFrame (within Berlin):\")\n",
    "              print(agent_home_locations_gdf.head())\n",
    "\n",
    "# Now agent_home_locations_gdf contains home locations of `num_agents_to_select_in_berlin` (or fewer if not available)\n",
    "# agents within Berlin, selected to be spatially distributed,\n",
    "# and its CRS matches that of berlin_outline_gdf (EPSG:3035).\n",
    "# You can proceed with spatial operations like joining with the NO2 raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 3286,
     "status": "aborted",
     "timestamp": 1750337209470,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "_ZDJLEyWJgaX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame exported to csv\n"
     ]
    }
   ],
   "source": [
    "# prompt: export the agent_homes_df to csv\n",
    "agents_in_berlin_selection_output_path = \"berlin_output/agents_berlin_city_selected3000.csv\"\n",
    "\n",
    "# Now call .to_csv() on the DataFrame\n",
    "agent_home_locations_gdf.to_csv(base_folder+agents_in_berlin_selection_output_path, index=False)\n",
    "print(\"DataFrame exported to csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FASbdmDNLKqj"
   },
   "source": [
    "### Get NO2 value at the home locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9955,
     "status": "ok",
     "timestamp": 1750336425172,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "vrDKXIMBJvYX",
    "outputId": "54d51e54-1a96-4a8d-cab1-5513a04bf692"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import rasterio\n",
    "except ImportError:\n",
    "    !pip install rasterio\n",
    "    import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76136,
     "status": "ok",
     "timestamp": 1750337364754,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "R1F1OfIRLb20",
    "outputId": "18958bb4-c2b1-46f8-ec2c-b2bfd73ba2cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO2 Raster CRS: EPSG:3035\n",
      "\n",
      "NO2 values sampled at agent home locations:\n",
      "      agent_id   x_matsim    y_matsim  NO2_value\n",
      "0  bb_00afd203  811364.91  5814352.60   8.339029\n",
      "1  bb_01957e69  780852.22  5812441.37       -inf\n",
      "2  bb_01ccc469  792574.51  5815250.61       -inf\n",
      "3  bb_02a9b568  810986.06  5831918.25       -inf\n",
      "4  bb_02fdaa13  810738.80  5814317.68  10.251132\n",
      "\n",
      "Summary statistics for sampled NO2 values:\n",
      "count    3.769910e+05\n",
      "mean             -inf\n",
      "std               NaN\n",
      "min              -inf\n",
      "25%      1.332574e+01\n",
      "50%      1.567789e+01\n",
      "75%      1.843211e+01\n",
      "max      2.154372e+01\n",
      "Name: NO2_value, dtype: float64\n",
      "The GeoDataFrame `agent_home_locations_gdf` now contains the 'NO2_value' assigned to each selected agent.\n"
     ]
    }
   ],
   "source": [
    "# Define the CRS of the MATSim coordinates (ETRS89 / UTM zone 33N for Berlin)\n",
    "matsim_crs = 'EPSG:25832'\n",
    "# Define the target CRS for spatial operations (ETRS89-LAEA for Europe, matches the raster)\n",
    "target_crs_for_raster = 'EPSG:3035'\n",
    "\n",
    "#process all agents within Berlin (without selection a subset)\n",
    "agent_home_locations_gdf = all_eligible_agents_gdf\n",
    "\n",
    "# Load the NO2 raster\n",
    "try:\n",
    "    with rasterio.open(base_folder+NO2_annual_raster_Berlin) as src:\n",
    "        raster_crs = src.crs\n",
    "        print(f\"NO2 Raster CRS: {raster_crs}\")\n",
    "\n",
    "        # Read the first band and transform\n",
    "        no2_band = src.read(1)\n",
    "        raster_transform = src.transform\n",
    "\n",
    "        # Check if raster CRS matches the target CRS, reproject agent points if necessary\n",
    "        if raster_crs != target_crs_for_raster:\n",
    "            print(f\"Warning: Raster CRS ({raster_crs}) does not match target CRS ({target_crs_for_raster}). Reprojecting agent home locations.\")\n",
    "            # Reproject the agent home locations GeoDataFrame to match the raster CRS\n",
    "            # Assuming agent_home_locations_gdf is already loaded and has a CRS set\n",
    "            # (it should have EPSG:3035 from the previous step, but reprojecting is safer)\n",
    "            if agent_home_locations_gdf.crs is None:\n",
    "                print(\"Error: agent_home_locations_gdf has no CRS. Cannot reproject.\")\n",
    "                # Handle this error: e.g., set CRS or skip raster sampling\n",
    "            elif agent_home_locations_gdf.crs != raster_crs:\n",
    "                agent_home_locations_gdf = agent_home_locations_gdf.to_crs(raster_crs)\n",
    "                print(f\"Agent Home Locations GeoDataFrame reprojected to Raster CRS: {agent_home_locations_gdf.crs}\")\n",
    "            else:\n",
    "                 print(\"Agent Home Locations GeoDataFrame CRS matches Raster CRS.\")\n",
    "\n",
    "        # Check if agent_home_locations_gdf is empty or missing required columns\n",
    "        if agent_home_locations_gdf.empty or 'geometry' not in agent_home_locations_gdf.columns:\n",
    "             print(\"Agent home locations GeoDataFrame is empty or missing 'geometry' column. Cannot sample raster.\")\n",
    "             # Add a placeholder column with None values if the dataframe exists but is empty\n",
    "             if 'NO2_value' not in agent_home_locations_gdf.columns:\n",
    "                  agent_home_locations_gdf['NO2_value'] = None\n",
    "        else:\n",
    "            # Function to get raster value at a given point geometry\n",
    "            # This function uses the rasterio's sample method which handles coordinates directly\n",
    "            def get_raster_value_at_point(point_geometry, raster_source):\n",
    "                # rasterio.sample takes a list of point tuples [(x, y), ...]\n",
    "                # The point_geometry is a shapely Point, get its coordinates\n",
    "                if point_geometry is None or point_geometry.is_empty:\n",
    "                    return None\n",
    "                try:\n",
    "                    # Use src.sample directly with the point geometry.\n",
    "                    # src.sample expects points in the source CRS, which the reprojected\n",
    "                    # agent_home_locations_gdf['geometry'] should now match.\n",
    "                    value_generator = raster_source.sample([(point_geometry.x, point_geometry.y)])\n",
    "                    # src.sample returns an iterable, usually with one item for one point\n",
    "                    value = next(value_generator)[0] # Get the value from the array (band 1)\n",
    "                    # Handle potential NoData values if specified in the raster\n",
    "                    if src.nodata is not None and value == src.nodata:\n",
    "                         return None # Treat NoData as None\n",
    "                    return value\n",
    "                except Exception as e:\n",
    "                    print(f\"Error sampling raster at point ({point_geometry.x}, {point_geometry.y}): {e}\")\n",
    "                    return None\n",
    "\n",
    "            # Apply the function to each row in the agent_home_locations_gdf\n",
    "            # Make sure the GeoDataFrame has a 'geometry' column with Point objects in the raster CRS\n",
    "            agent_home_locations_gdf['NO2_value'] = agent_home_locations_gdf['geometry'].apply(\n",
    "                 lambda geom: get_raster_value_at_point(geom, src)\n",
    "            )\n",
    "\n",
    "            print(\"\\nNO2 values sampled at agent home locations:\")\n",
    "            print(agent_home_locations_gdf[['agent_id', 'x_matsim', 'y_matsim', 'NO2_value']].head())\n",
    "\n",
    "            # Optional: Show summary statistics for the sampled NO2 values\n",
    "            print(\"\\nSummary statistics for sampled NO2 values:\")\n",
    "            print(agent_home_locations_gdf['NO2_value'].describe())\n",
    "\n",
    "\n",
    "except rasterio.errors.RasterioIOError as e:\n",
    "    print(f\"Error opening NO2 raster file: {e}\")\n",
    "    print(\"Cannot proceed with raster sampling.\")\n",
    "    # Ensure the NO2_value column exists even if the raster fails to load\n",
    "    if 'NO2_value' not in agent_home_locations_gdf.columns:\n",
    "         agent_home_locations_gdf['NO2_value'] = None\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred during raster processing: {e}\")\n",
    "    # Ensure the NO2_value column exists even if other errors occur\n",
    "    if 'NO2_value' not in agent_home_locations_gdf.columns:\n",
    "         agent_home_locations_gdf['NO2_value'] = None\n",
    "\n",
    "\n",
    "print(\"The GeoDataFrame `agent_home_locations_gdf` now contains the 'NO2_value' assigned to each selected agent.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1750337380524,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "EkHpbcwxMGqX",
    "outputId": "db71a0c7-403a-423f-ed52-d64090fbd1ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replacing -inf NO2_value with NaN...\n",
      "Initial -inf count: 3035\n",
      "Final NaN count (includes original NaNs and replaced -inf): 3035\n",
      "\n",
      "Agent Home Locations GeoDataFrame after replacing -inf with NaN:\n",
      "      agent_id  NO2_value\n",
      "0  bb_00afd203   8.339029\n",
      "1  bb_01957e69        NaN\n",
      "2  bb_01ccc469        NaN\n",
      "3  bb_02a9b568        NaN\n",
      "4  bb_02fdaa13  10.251132\n",
      "\n",
      "Summary statistics after replacement:\n",
      "count    373956.000000\n",
      "mean         15.736704\n",
      "std           3.167824\n",
      "min           2.357919\n",
      "25%          13.381557\n",
      "50%          15.694091\n",
      "75%          18.448425\n",
      "max          21.543722\n",
      "Name: NO2_value, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace -inf values in the 'NO2_value' column with NaN\n",
    "# -inf values often appear in raster sampling when the point falls exactly on a pixel boundary or due to interpolation issues at edges/nodata areas.\n",
    "\n",
    "# Check if the column exists and is numeric\n",
    "if 'NO2_value' in agent_home_locations_gdf.columns and pd.api.types.is_numeric_dtype(agent_home_locations_gdf['NO2_value']):\n",
    "    print(\"Replacing -inf NO2_value with NaN...\")\n",
    "    initial_neg_inf_count = (agent_home_locations_gdf['NO2_value'] == -np.inf).sum()\n",
    "\n",
    "    # Use replace method or direct boolean indexing\n",
    "    # Using replace is often cleaner\n",
    "    agent_home_locations_gdf['NO2_value'] = agent_home_locations_gdf['NO2_value'].replace(-np.inf, np.nan)\n",
    "\n",
    "    # Alternatively, using boolean indexing:\n",
    "    # agent_home_locations_gdf.loc[agent_home_locations_gdf['NO2_value'] == -np.inf, 'NO2_value'] = np.nan\n",
    "\n",
    "    final_nan_count = agent_home_locations_gdf['NO2_value'].isna().sum()\n",
    "    print(f\"Initial -inf count: {initial_neg_inf_count}\")\n",
    "    print(f\"Final NaN count (includes original NaNs and replaced -inf): {final_nan_count}\")\n",
    "else:\n",
    "    print(\"'NO2_value' column not found or is not numeric in agent_home_locations_gdf. Skipping -inf replacement.\")\n",
    "\n",
    "# Verify the changes\n",
    "print(\"\\nAgent Home Locations GeoDataFrame after replacing -inf with NaN:\")\n",
    "print(agent_home_locations_gdf[['agent_id', 'NO2_value']].head())\n",
    "\n",
    "# Optional: Check descriptive statistics again\n",
    "print(\"\\nSummary statistics after replacement:\")\n",
    "print(agent_home_locations_gdf['NO2_value'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7852,
     "status": "ok",
     "timestamp": 1750337430553,
     "user": {
      "displayName": "Lucie Stará",
      "userId": "15970413653442924951"
     },
     "user_tz": -120
    },
    "id": "18FWneNJMVJV",
    "outputId": "1154c309-4581-45d1-cdaa-9d6b1503ba61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent data with NO2 values saved to berlin_output/agents_berlin_city_with_NO2_v2.csv\n"
     ]
    }
   ],
   "source": [
    "# Now agent_home_locations_gdf has a 'NO2_value' column\n",
    "# Save the GeoDataFrame with the new NO2 column if needed\n",
    "agents_with_no2_output_path = \"berlin_output/agents_berlin_city_with_NO2_v2.csv\"\n",
    "# Save as CSV, geometry will be converted to WKT by default (or just drop it if not needed)\n",
    "agent_home_locations_gdf.to_csv(base_folder+agents_with_no2_output_path, index=False)\n",
    "print(f\"Agent data with NO2 values saved to {agents_with_no2_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H73oXF3fMevF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOjKmBj1QvcI4V6KvN0Obj6",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
